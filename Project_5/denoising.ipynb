{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0deed8",
   "metadata": {},
   "source": [
    "# Add various kinds of noise then test denoising methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2f070d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def load_image_keep_channels(path):\n",
    "    # preserve number of channels and alpha if present\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    # convert 4-channel BGRA -> BGR (drop alpha) for metric comparisons\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    return img\n",
    "\n",
    "def to_uint8(img):\n",
    "    # convert floats to uint8 if needed (assume values in 0..1 for floats)\n",
    "    if img.dtype == np.float32 or img.dtype == np.float64:\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def compute_metrics(ref_path, test_path):\n",
    "    A = load_image_keep_channels(ref_path)\n",
    "    B = load_image_keep_channels(test_path)\n",
    "\n",
    "    # If either is grayscale image read as 2D, keep as 2D. If one is 2D and the other 3D,\n",
    "    # convert 3D to grayscale to compare apples-to-apples (or replicate channels)\n",
    "    if A.ndim == 2 and B.ndim == 3:\n",
    "        B = cv2.cvtColor(B, cv2.COLOR_BGR2GRAY)\n",
    "    elif A.ndim == 3 and B.ndim == 2:\n",
    "        A = cv2.cvtColor(A, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    A = to_uint8(A)\n",
    "    B = to_uint8(B)\n",
    "\n",
    "    if A.shape != B.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {A.shape} vs {B.shape}\")\n",
    "\n",
    "    # data_range for uint8 images\n",
    "    data_range = 255 if A.dtype == np.uint8 else (A.max() - A.min())\n",
    "\n",
    "    # PSNR works for both grayscale and color\n",
    "    psnr_val = psnr(A, B, data_range=data_range)\n",
    "\n",
    "    # For SSIM: specify channel_axis for multichannel arrays\n",
    "    if A.ndim == 3:\n",
    "        ssim_val = ssim(A, B, data_range=data_range, channel_axis=-1)\n",
    "    else:\n",
    "        ssim_val = ssim(A, B, data_range=data_range)\n",
    "\n",
    "    return psnr_val, ssim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "349a92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGN(image, mean=0, sigma=25):\n",
    "    \"\"\"Add Additive White Gaussian Noise to an image (uint8 0–255).\"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    gauss = np.random.normal(mean, sigma, image.shape).astype(np.float32)\n",
    "    noisy = image + gauss\n",
    "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "    return noisy\n",
    "\n",
    "def impulse_noise(image, prob=0.05):\n",
    "    \"\"\"Add Impulse Noise (Salt and Pepper Noise) to an image.\"\"\"\n",
    "    noisy_image = image.copy()\n",
    "    black = 0\n",
    "    white = 255\n",
    "    probs = np.random.rand(*image.shape)\n",
    "    noisy_image[probs < (prob / 2)] = black\n",
    "    noisy_image[probs > 1 - (prob / 2)] = white\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d51bd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# add noise to image and save them to respective folders (AWGN and Impulse Noise)\n",
    "def add_noise_and_save(input_image_path, awgn_folder, impulse_folder):\n",
    "    if not os.path.exists(awgn_folder):\n",
    "        os.makedirs(awgn_folder)\n",
    "    if not os.path.exists(impulse_folder):\n",
    "        os.makedirs(impulse_folder)\n",
    "\n",
    "    image = load_image_keep_channels(input_image_path)\n",
    "\n",
    "    awgn_image = AWGN(image)\n",
    "    impulse_image = impulse_noise(image)\n",
    "\n",
    "    awgn_image_path = os.path.join(awgn_folder, os.path.basename(input_image_path))\n",
    "    impulse_image_path = os.path.join(impulse_folder, os.path.basename(input_image_path))\n",
    "\n",
    "    cv2.imwrite(awgn_image_path, awgn_image)\n",
    "    cv2.imwrite(impulse_image_path, impulse_image)\n",
    "\n",
    "    return awgn_image_path, impulse_image_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1502c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image                PSNR_AWGN       SSIM_AWGN       PSNR_Impulse    SSIM_Impulse   \n",
      "airplane.bmp         20.3525         0.2918          17.8916         0.3511         \n",
      "boats.bmp            20.3609         0.3199          18.4382         0.3505         \n",
      "BoatsColor.bmp       20.5026         0.3356          18.1883         0.3685         \n",
      "checkerboard.bmp     23.2040         0.2957          16.1239         0.4334         \n",
      "goldhill.bmp         20.4629         0.3402          18.0102         0.3783         \n"
     ]
    }
   ],
   "source": [
    "# add noise to all the .bmp images in STI/Classic\n",
    "input_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\original'\n",
    "awgn_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\AWGN'\n",
    "impulse_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\Impulse'\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.bmp'):\n",
    "        input_image_path = os.path.join(input_folder, filename)\n",
    "        add_noise_and_save(input_image_path, awgn_folder, impulse_folder)\n",
    "\n",
    "#calculate PSNR and SSIM for noisy images\n",
    "results = []\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.bmp'):\n",
    "        input_image_path = os.path.join(input_folder, filename)\n",
    "        awgn_image_path = os.path.join(awgn_folder, filename)\n",
    "        impulse_image_path = os.path.join(impulse_folder, filename)\n",
    "\n",
    "        psnr_awgn, ssim_awgn = compute_metrics(input_image_path, awgn_image_path)\n",
    "        psnr_impulse, ssim_impulse = compute_metrics(input_image_path, impulse_image_path)\n",
    "\n",
    "        results.append((filename, psnr_awgn, ssim_awgn, psnr_impulse, ssim_impulse))\n",
    "# Print results in tabular format\n",
    "print(f\"{'Image':<20} {'PSNR_AWGN':<15} {'SSIM_AWGN':<15} {'PSNR_Impulse':<15} {'SSIM_Impulse':<15}\")\n",
    "for row in results:\n",
    "    print(f\"{row[0]:<20} {row[1]:<15.4f} {row[2]:<15.4f} {row[3]:<15.4f} {row[4]:<15.4f}\")\n",
    "\n",
    "# Visualize one example\n",
    "example_image = os.path.join(input_folder, 'boatsColor.bmp')\n",
    "awgn_image_path = os.path.join(awgn_folder, 'boatsColor.bmp')\n",
    "impulse_image_path = os.path.join(impulse_folder, 'boatsColor.bmp')\n",
    "original = load_image_keep_channels(example_image)\n",
    "awgn_image = load_image_keep_channels(awgn_image_path)\n",
    "impulse_image = load_image_keep_channels(impulse_image_path)\n",
    "cv2.imshow('Original Image', original)\n",
    "cv2.imshow('AWGN Image', awgn_image)\n",
    "cv2.imshow('Impulse Noise Image', impulse_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c03d49d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma: 1, PSNR: 46.88, SSIM: 0.9913\n",
      "Sigma: 6, PSNR: 32.54, SSIM: 0.8003\n",
      "Sigma: 11, PSNR: 27.34, SSIM: 0.5989\n",
      "Sigma: 16, PSNR: 24.15, SSIM: 0.4641\n",
      "Sigma: 21, PSNR: 21.84, SSIM: 0.3724\n",
      "Sigma: 26, PSNR: 20.02, SSIM: 0.3082\n"
     ]
    }
   ],
   "source": [
    "boats_path = 'C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\boats.bmp'\n",
    "for i in range(1, 30, 5):\n",
    "    noisy_image = AWGN(load_image_keep_channels(boats_path), sigma=i)\n",
    "    noisy_image_path = f'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\AWGN\\\\boats_sigma_{i}.bmp'\n",
    "    cv2.imwrite(noisy_image_path, noisy_image)\n",
    "    psnr_val, ssim_val = compute_metrics(boats_path, noisy_image_path)\n",
    "    print(f'Sigma: {i}, PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e59bcfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "noisy_path = \"C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\Impulse\\\\checkerboard.bmp\"\n",
    "den_path = \"C:\\\\ImageProcessing\\\\Project_5\\\\Checker_ChatGPT.png\"\n",
    "orig_path = \"C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\checkerboard.bmp\" \n",
    "\n",
    "orig = cv2.imread(orig_path)      # or .bmp, .jpg, etc.\n",
    "den = cv2.imread(den_path)\n",
    "noisy = cv2.imread(noisy_path)\n",
    "\n",
    "h, w = orig.shape[:2]\n",
    "den_resized = cv2.resize(den, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imwrite(\"denoised_match.bmp\", den_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a91eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invert checkerboard creation to save as BMP\n",
    "den_resized = cv2.imread(\"denoised_match.bmp\")\n",
    "den_resized_inverse = cv2.bitwise_not(den_resized)\n",
    "cv2.imwrite(\"denoised_match_inverse.bmp\", den_resized_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79c9af9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy Image - PSNR: 16.12, SSIM: 0.4334\n",
      "ChatGPT Denoised Image - PSNR: 45.93, SSIM: 0.8684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "psnr_noisy, ssim_noisy = compute_metrics(orig_path, noisy_path)\n",
    "print(f'Noisy Image - PSNR: {psnr_noisy:.2f}, SSIM: {ssim_noisy:.4f}')\n",
    "chat_psnr, chat_ssim = compute_metrics(orig_path, \"C:\\\\ImageProcessing\\\\Project_5\\\\denoised_match_inverse.bmp\")\n",
    "print(f'ChatGPT Denoised Image - PSNR: {chat_psnr:.2f}, SSIM: {chat_ssim:.4f}')\n",
    "cv2.imshow('Original Checkerboard', orig)\n",
    "cv2.imshow('Noisy Checkerboard', noisy)\n",
    "cv2.imshow('Denoised Checkerboard', den_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af021d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinv as dinv\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Pretrained DRUNet from deepinv (downloads weights on first use)\n",
    "drunet = dinv.models.DRUNet(pretrained=\"download\", device=device).eval()\n",
    "\n",
    "\n",
    "\n",
    "def DRUNet_denoise(noisy_image, sigma=0.1, device=device):\n",
    "    \"\"\"\n",
    "    Denoise a noisy image using DRUNet.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    noisy_image : np.ndarray\n",
    "        HxW (gray) or HxWx3 (color), usually uint8 in [0,255] or float in [0,1].\n",
    "    sigma : float\n",
    "        AWGN std *in [0,1]* matching how you added noise.\n",
    "        e.g. AWGN with sigma=25 on uint8 -> sigma = 25/255 ≈ 0.098.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- 1) Ensure we have 3 channels -----\n",
    "    if noisy_image.ndim == 2:\n",
    "        # gray -> 3-channel by replication so DRUNet (RGB) can process it\n",
    "        noisy_image = np.stack([noisy_image] * 3, axis=-1)\n",
    "    elif noisy_image.ndim == 3 and noisy_image.shape[2] == 1:\n",
    "        noisy_image = np.repeat(noisy_image, 3, axis=2)\n",
    "\n",
    "    # If BGR from OpenCV, convert to RGB (DRUNet was trained on RGB)\n",
    "    noisy_rgb = noisy_image\n",
    "    if noisy_rgb.dtype == np.uint8:\n",
    "        noisy_rgb = noisy_rgb.astype(np.float32) / 255.0\n",
    "\n",
    "    # ----- 2) Numpy -> torch tensor, shape (B,C,H,W) -----\n",
    "    x = torch.from_numpy(noisy_rgb).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "    # ----- 3) Run DRUNet -----\n",
    "    with torch.no_grad():\n",
    "        # DRUNet expects sigma in [0,1] for images in [0,1]\n",
    "        x_denoised = drunet(x, sigma=sigma)\n",
    "\n",
    "    # ----- 4) Back to numpy -----\n",
    "    denoised = x_denoised.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    denoised = np.clip(denoised, 0.0, 1.0)\n",
    "\n",
    "    # Back to uint8 BGR for OpenCV display/saving\n",
    "    denoised_uint8 = (denoised * 255.0).round().astype(np.uint8)\n",
    "\n",
    "    # convert back to BGR if you want consistent OpenCV handling\n",
    "    denoised_bgr = denoised_uint8  # if your input was RGB; if it was BGR, swap here\n",
    "\n",
    "    return denoised_bgr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b63e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRUNet Denoised BoatsColor.bmp - PSNR: 32.81, SSIM: 0.8755\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sigma_norm = 25/255  # for AWGN with sigma=25 on uint8 images\n",
    "img = cv2.imread(\"C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\AWGN\\\\BoatsColor.bmp\")\n",
    "denoised = DRUNet_denoise(img, sigma=sigma_norm, device=device)\n",
    "cv2.imwrite(\"DRUNet_denoised_BoatsColor.bmp\", denoised)\n",
    "psnr_value, ssim_value = (compute_metrics(\"C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\BoatsColor.bmp\", \"DRUNet_denoised_BoatsColor.bmp\"))\n",
    "print(f\"DRUNet Denoised BoatsColor.bmp - PSNR: {psnr_value:.2f}, SSIM: {ssim_value:.4f}\")\n",
    "cv2.imshow(\"Noisy\", img)\n",
    "cv2.imshow(\"DRUNet Denoised\", denoised)\n",
    "cv2.imshow(\"Original\", cv2.imread(\"C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\BoatsColor.bmp\"))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ipvenv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
