{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0deed8",
   "metadata": {},
   "source": [
    "# Add various kinds of noise then test denoising methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f070d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def load_image_keep_channels(path):\n",
    "    # preserve number of channels and alpha if present\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    # convert 4-channel BGRA -> BGR (drop alpha) for metric comparisons\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    return img\n",
    "\n",
    "def to_uint8(img):\n",
    "    # convert floats to uint8 if needed (assume values in 0..1 for floats)\n",
    "    if img.dtype == np.float32 or img.dtype == np.float64:\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def compute_metrics(ref_path, test_path):\n",
    "    A = load_image_keep_channels(ref_path)\n",
    "    B = load_image_keep_channels(test_path)\n",
    "\n",
    "    # If either is grayscale image read as 2D, keep as 2D. If one is 2D and the other 3D,\n",
    "    # convert 3D to grayscale to compare apples-to-apples (or replicate channels)\n",
    "    if A.ndim == 2 and B.ndim == 3:\n",
    "        B = cv2.cvtColor(B, cv2.COLOR_BGR2GRAY)\n",
    "    elif A.ndim == 3 and B.ndim == 2:\n",
    "        A = cv2.cvtColor(A, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    A = to_uint8(A)\n",
    "    B = to_uint8(B)\n",
    "\n",
    "    if A.shape != B.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {A.shape} vs {B.shape}\")\n",
    "\n",
    "    # data_range for uint8 images\n",
    "    data_range = 255 if A.dtype == np.uint8 else (A.max() - A.min())\n",
    "\n",
    "    # PSNR works for both grayscale and color\n",
    "    psnr_val = psnr(A, B, data_range=data_range)\n",
    "\n",
    "    # For SSIM: specify channel_axis for multichannel arrays\n",
    "    if A.ndim == 3:\n",
    "        ssim_val = ssim(A, B, data_range=data_range, channel_axis=-1)\n",
    "    else:\n",
    "        ssim_val = ssim(A, B, data_range=data_range)\n",
    "\n",
    "    return psnr_val, ssim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349a92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGN(image, mean=0, sigma=25):\n",
    "    \"\"\"Add Additive White Gaussian Noise to an image (uint8 0–255).\"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    gauss = np.random.normal(mean, sigma, image.shape).astype(np.float32)\n",
    "    noisy = image + gauss\n",
    "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "    return noisy\n",
    "\n",
    "def impulse_noise(image, prob=0.05):\n",
    "    \"\"\"Add Impulse Noise (Salt and Pepper Noise) to an image.\"\"\"\n",
    "    noisy_image = image.copy()\n",
    "    black = 0\n",
    "    white = 255\n",
    "    probs = np.random.rand(*image.shape)\n",
    "    noisy_image[probs < (prob / 2)] = black\n",
    "    noisy_image[probs > 1 - (prob / 2)] = white\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51bd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# add noise to image and save them to respective folders (AWGN and Impulse Noise)\n",
    "def add_noise_and_save(input_image_path, awgn_folder, impulse_folder):\n",
    "    if not os.path.exists(awgn_folder):\n",
    "        os.makedirs(awgn_folder)\n",
    "    if not os.path.exists(impulse_folder):\n",
    "        os.makedirs(impulse_folder)\n",
    "\n",
    "    image = load_image_keep_channels(input_image_path)\n",
    "\n",
    "    awgn_image = AWGN(image)\n",
    "    impulse_image = impulse_noise(image)\n",
    "\n",
    "    awgn_image_path = os.path.join(awgn_folder, os.path.basename(input_image_path))\n",
    "    impulse_image_path = os.path.join(impulse_folder, os.path.basename(input_image_path))\n",
    "\n",
    "    cv2.imwrite(awgn_image_path, awgn_image)\n",
    "    cv2.imwrite(impulse_image_path, impulse_image)\n",
    "\n",
    "    return awgn_image_path, impulse_image_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1502c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image                PSNR_AWGN       SSIM_AWGN       PSNR_Impulse    SSIM_Impulse   \n",
      "airplane.bmp         20.3470         0.2918          17.8707         0.3497         \n",
      "boats.bmp            20.3563         0.3193          18.4608         0.3516         \n",
      "BoatsColor.bmp       20.4981         0.3353          18.1548         0.3675         \n",
      "checkerboard.bmp     23.1475         0.2945          16.1406         0.4347         \n",
      "goldhill.bmp         20.4621         0.3400          18.0472         0.3795         \n"
     ]
    }
   ],
   "source": [
    "# add noise to all the .bmp images in STI/Classic\n",
    "input_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\original'\n",
    "awgn_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\AWGN'\n",
    "impulse_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\Impulse'\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.bmp'):\n",
    "        input_image_path = os.path.join(input_folder, filename)\n",
    "        add_noise_and_save(input_image_path, awgn_folder, impulse_folder)\n",
    "\n",
    "#calculate PSNR and SSIM for noisy images\n",
    "results = []\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.bmp'):\n",
    "        input_image_path = os.path.join(input_folder, filename)\n",
    "        awgn_image_path = os.path.join(awgn_folder, filename)\n",
    "        impulse_image_path = os.path.join(impulse_folder, filename)\n",
    "\n",
    "        psnr_awgn, ssim_awgn = compute_metrics(input_image_path, awgn_image_path)\n",
    "        psnr_impulse, ssim_impulse = compute_metrics(input_image_path, impulse_image_path)\n",
    "\n",
    "        results.append((filename, psnr_awgn, ssim_awgn, psnr_impulse, ssim_impulse))\n",
    "# Print results in tabular format\n",
    "print(f\"{'Image':<20} {'PSNR_AWGN':<15} {'SSIM_AWGN':<15} {'PSNR_Impulse':<15} {'SSIM_Impulse':<15}\")\n",
    "for row in results:\n",
    "    print(f\"{row[0]:<20} {row[1]:<15.4f} {row[2]:<15.4f} {row[3]:<15.4f} {row[4]:<15.4f}\")\n",
    "\n",
    "# Visualize one example\n",
    "example_image = os.path.join(input_folder, 'boatsColor.bmp')\n",
    "awgn_image_path = os.path.join(awgn_folder, 'boatsColor.bmp')\n",
    "impulse_image_path = os.path.join(impulse_folder, 'boatsColor.bmp')\n",
    "original = load_image_keep_channels(example_image)\n",
    "awgn_image = load_image_keep_channels(awgn_image_path)\n",
    "impulse_image = load_image_keep_channels(impulse_image_path)\n",
    "cv2.imshow('Original Image', original)\n",
    "cv2.imshow('AWGN Image', awgn_image)\n",
    "cv2.imshow('Impulse Noise Image', impulse_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03d49d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma: 1, PSNR: 46.87, SSIM: 0.9913\n",
      "Sigma: 6, PSNR: 32.52, SSIM: 0.7997\n",
      "Sigma: 11, PSNR: 27.32, SSIM: 0.5977\n",
      "Sigma: 16, PSNR: 24.14, SSIM: 0.4634\n",
      "Sigma: 21, PSNR: 21.82, SSIM: 0.3720\n",
      "Sigma: 26, PSNR: 20.04, SSIM: 0.3082\n"
     ]
    }
   ],
   "source": [
    "boats_path = 'C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\boats.bmp'\n",
    "for i in range(1, 30, 5):\n",
    "    noisy_image = AWGN(load_image_keep_channels(boats_path), sigma=i)\n",
    "    noisy_image_path = f'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\AWGN\\\\boats_sigma_{i}.bmp'\n",
    "    cv2.imwrite(noisy_image_path, noisy_image)\n",
    "    psnr_val, ssim_val = compute_metrics(boats_path, noisy_image_path)\n",
    "    print(f'Sigma: {i}, PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bcfdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m noisy \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(noisy_path)\n\u001b[0;32m     11\u001b[0m h, w \u001b[38;5;241m=\u001b[39m orig\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m den_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_CUBIC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdenoised_match.bmp\u001b[39m\u001b[38;5;124m\"\u001b[39m, den_resized)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "\n",
    "# noisy_path = \"C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\Impulse\\\\checkerboard.bmp\"\n",
    "# den_path = \"C:\\\\ImageProcessing\\\\Project_5\\\\Checker_ChatGPT.png\"\n",
    "# orig_path = \"C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\checkerboard.bmp\" \n",
    "\n",
    "# orig = cv2.imread(orig_path)      # or .bmp, .jpg, etc.\n",
    "# den = cv2.imread(den_path)\n",
    "# noisy = cv2.imread(noisy_path)\n",
    "\n",
    "# h, w = orig.shape[:2]\n",
    "# den_resized = cv2.resize(den, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "# cv2.imwrite(\"denoised_match.bmp\", den_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invert checkerboard creation to save as BMP\n",
    "den_resized = cv2.imread(\"denoised_match.bmp\")\n",
    "den_resized_inverse = cv2.bitwise_not(den_resized)\n",
    "cv2.imwrite(\"denoised_match_inverse.bmp\", den_resized_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c9af9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy Image - PSNR: 16.14, SSIM: 0.4347\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "C:\\ImageProcessing\\Project_5\\denoised_match_inverse.bmp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m psnr_noisy, ssim_noisy \u001b[38;5;241m=\u001b[39m compute_metrics(orig_path, noisy_path)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoisy Image - PSNR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpsnr_noisy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, SSIM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mssim_noisy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m chat_psnr, chat_ssim \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mImageProcessing\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mProject_5\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdenoised_match_inverse.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChatGPT Denoised Image - PSNR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat_psnr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, SSIM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat_ssim\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Checkerboard\u001b[39m\u001b[38;5;124m'\u001b[39m, orig)\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(ref_path, test_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_metrics\u001b[39m(ref_path, test_path):\n\u001b[0;32m     26\u001b[0m     A \u001b[38;5;241m=\u001b[39m load_image_keep_channels(ref_path)\n\u001b[1;32m---> 27\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[43mload_image_keep_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# If either is grayscale image read as 2D, keep as 2D. If one is 2D and the other 3D,\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# convert 3D to grayscale to compare apples-to-apples (or replicate channels)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m B\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m, in \u001b[0;36mload_image_keep_channels\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# convert 4-channel BGRA -> BGR (drop alpha) for metric comparisons\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: C:\\ImageProcessing\\Project_5\\denoised_match_inverse.bmp"
     ]
    }
   ],
   "source": [
    "\n",
    "psnr_noisy, ssim_noisy = compute_metrics(orig_path, noisy_path)\n",
    "print(f'Noisy Image - PSNR: {psnr_noisy:.2f}, SSIM: {ssim_noisy:.4f}')\n",
    "chat_psnr, chat_ssim = compute_metrics(orig_path, \"C:\\\\ImageProcessing\\\\Project_5\\\\denoised_match_inverse.bmp\")\n",
    "print(f'ChatGPT Denoised Image - PSNR: {chat_psnr:.2f}, SSIM: {chat_ssim:.4f}')\n",
    "cv2.imshow('Original Checkerboard', orig)\n",
    "cv2.imshow('Noisy Checkerboard', noisy)\n",
    "cv2.imshow('Denoised Checkerboard', den_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af021d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ImageProcessing\\.ipvenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import deepinv as dinv\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Pretrained DRUNet from deepinv (downloads weights on first use)\n",
    "drunet = dinv.models.DRUNet(pretrained=\"download\", device=device).eval()\n",
    "\n",
    "\n",
    "\n",
    "def DRUNet_denoise(noisy_image, sigma=0.1, device=device):\n",
    "    \"\"\"\n",
    "    Denoise a noisy image using DRUNet.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    noisy_image : np.ndarray\n",
    "        HxW (gray) or HxWx3 (color), usually uint8 in [0,255] or float in [0,1].\n",
    "    sigma : float\n",
    "        AWGN std *in [0,1]* matching how you added noise.\n",
    "        e.g. AWGN with sigma=25 on uint8 -> sigma = 25/255 ≈ 0.098.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- 1) Ensure we have 3 channels -----\n",
    "    if noisy_image.ndim == 2:\n",
    "        # gray -> 3-channel by replication so DRUNet (RGB) can process it\n",
    "        noisy_image = np.stack([noisy_image] * 3, axis=-1)\n",
    "    elif noisy_image.ndim == 3 and noisy_image.shape[2] == 1:\n",
    "        noisy_image = np.repeat(noisy_image, 3, axis=2)\n",
    "\n",
    "    # If BGR from OpenCV, convert to RGB (DRUNet was trained on RGB)\n",
    "    noisy_rgb = noisy_image\n",
    "    if noisy_rgb.dtype == np.uint8:\n",
    "        noisy_rgb = noisy_rgb.astype(np.float32) / 255.0\n",
    "\n",
    "    # ----- 2) Numpy -> torch tensor, shape (B,C,H,W) -----\n",
    "    x = torch.from_numpy(noisy_rgb).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "    # ----- 3) Run DRUNet -----\n",
    "    with torch.no_grad():\n",
    "        # DRUNet expects sigma in [0,1] for images in [0,1]\n",
    "        x_denoised = drunet(x, sigma=sigma)\n",
    "\n",
    "    # ----- 4) Back to numpy -----\n",
    "    denoised = x_denoised.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    denoised = np.clip(denoised, 0.0, 1.0)\n",
    "\n",
    "    # Back to uint8 BGR for OpenCV display/saving\n",
    "    denoised_uint8 = (denoised * 255.0).round().astype(np.uint8)\n",
    "\n",
    "    # convert back to BGR if you want consistent OpenCV handling\n",
    "    denoised_bgr = denoised_uint8  # if your input was RGB; if it was BGR, swap here\n",
    "\n",
    "    return denoised_bgr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b63e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma: 5, PSNR: 20.91, SSIM: 0.3489\n",
      "Sigma: 10, PSNR: 22.22, SSIM: 0.3962\n",
      "Sigma: 15, PSNR: 24.87, SSIM: 0.5037\n",
      "Sigma: 20, PSNR: 29.27, SSIM: 0.6973\n",
      "Sigma: 25, PSNR: 32.81, SSIM: 0.8753\n",
      "Sigma: 30, PSNR: 32.31, SSIM: 0.8637\n",
      "Sigma: 35, PSNR: 31.75, SSIM: 0.8508\n",
      "Sigma: 40, PSNR: 31.21, SSIM: 0.8368\n",
      "Sigma: 45, PSNR: 30.71, SSIM: 0.8241\n",
      "Sigma: 50, PSNR: 30.25, SSIM: 0.8118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# find best sigma norm for DRUNet on AWGN noisy BoatsColor.bmp\n",
    "best_psnr = -np.inf\n",
    "best_sigma = None\n",
    "for sigma in range(20, 30, 1):\n",
    "    sigma_norm = sigma / 255.0\n",
    "    img = cv2.imread(\"C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\AWGN\\\\BoatsColor.bmp\")\n",
    "    denoised = DRUNet_denoise(img, sigma=sigma_norm, device=device)\n",
    "    cv2.imwrite(\"temp_denoised.bmp\", denoised)\n",
    "    psnr_value, ssim_value = compute_metrics(\"C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\BoatsColor.bmp\", \"temp_denoised.bmp\")\n",
    "    print(f\"Sigma: {sigma}, PSNR: {psnr_value:.2f}, SSIM: {ssim_value:.4f}\")\n",
    "    if psnr_value > best_psnr:\n",
    "        best_psnr = psnr_value\n",
    "        best_sigma = sigma_norm\n",
    "# cv2.imshow(\"Noisy\", img)\n",
    "# cv2.imshow(\"DRUNet Denoised\", denoised)\n",
    "# cv2.imshow(\"Original\", cv2.imread(\"C:\\\\ImageProcessing\\\\Project_5\\\\original\\\\BoatsColor.bmp\"))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3fb524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise all images in AWGN folder and save results\n",
    "awgn_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\noisy_images\\\\Impulse'\n",
    "denoised_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\denoised\\\\DRUNet'\n",
    "if not os.path.exists(denoised_folder):\n",
    "    os.makedirs(denoised_folder)\n",
    "for filename in os.listdir(awgn_folder):\n",
    "    if filename.endswith('.bmp'):\n",
    "        noisy_image_path = os.path.join(awgn_folder, filename)\n",
    "        img = cv2.imread(noisy_image_path)\n",
    "        denoised = DRUNet_denoise(img, sigma=sigma_norm, device=device)\n",
    "        denoised_image_path = os.path.join(denoised_folder, filename)\n",
    "        cv2.imwrite(denoised_image_path, denoised)\n",
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c4e35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PSNR and SSIM for denoised images and save as csv\n",
    "results = []\n",
    "denoised_folder = 'C:\\\\ImageProcessing\\\\Project_5\\\\denoised\\\\Impulse\\\\wiener_filtered_output'\n",
    "for filename in os.listdir(denoised_folder):\n",
    "    if filename.endswith('.bmp'):\n",
    "        denoised_image_path = os.path.join(denoised_folder, filename)\n",
    "        original_image_path = os.path.join(input_folder, filename)\n",
    "        psnr_val, ssim_val = compute_metrics(original_image_path, denoised_image_path)\n",
    "        results.append((filename, psnr_val, ssim_val))\n",
    "# CSV\n",
    "import csv\n",
    "csv_path = 'C:\\\\ImageProcessing\\\\Project_5\\\\denoised\\\\Impulse\\\\wiener_filtered_output\\\\denoising_results.csv'\n",
    "with open(csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Image', 'PSNR', 'SSIM'])\n",
    "    for row in results:\n",
    "        writer.writerow(row)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ipvenv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
